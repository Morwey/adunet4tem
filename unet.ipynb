{"cells":[{"cell_type":"markdown","source":["# Run code block below to initilization"],"metadata":{"id":"VOoND8UvG709"}},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"AVFQS2RuiNcH","executionInfo":{"status":"ok","timestamp":1715035006475,"user_tz":-120,"elapsed":2791,"user":{"displayName":"Xinwei Song","userId":"15192157271862011156"}}},"outputs":[],"source":["#@markdown ###Download a demo dataset\n","\n","import requests\n","import zipfile\n","import io\n","\n","# Define the Zenodo link\n","zenodo_link = \"https://zenodo.org/records/11123445/files/data.zip?download=1\"\n","\n","# Download the file\n","response = requests.get(zenodo_link)\n","zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n","\n","# Specify the destination folder for extraction\n","destination_folder = '/content'\n","\n","\n","# Extract the contents of the zip file to the destination folder\n","zip_file.extractall(destination_folder)\n","\n","# Close the zip file\n","zip_file.close()\n","\n","!rm -rf data/__MACOSX/\n","!rm -rf __MACOSX/"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","id":"v0N4UhuGTxON","executionInfo":{"status":"ok","timestamp":1715035319565,"user_tz":-120,"elapsed":6087,"user":{"displayName":"Xinwei Song","userId":"15192157271862011156"}}},"outputs":[],"source":["%%capture\n","#@markdown ### initilization\n","import torch\n","print(torch.__version__)\n","\n","!pip install csbdeep\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","def showimg(src_img,ref_img,matched_img):\n","    plt.figure(figsize=(10, 10))\n","\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(src_img, cmap='gray')\n","    plt.title('Source Image')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(ref_img, cmap='gray')\n","    plt.title('Reference Image')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(matched_img, cmap='gray')\n","    plt.title('Matched Image')\n","    plt.axis('off')\n","\n","    plt.show()\n","\n","def match_histograms(src_img, ref_img):\n","\n","    src_hist, src_bins = np.histogram(src_img.flatten(), 256, [0,256])\n","    ref_hist, ref_bins = np.histogram(ref_img.flatten(), 256, [0,256])\n","\n","    src_cdf = src_hist.cumsum() / src_hist.sum()\n","    ref_cdf = ref_hist.cumsum() / ref_hist.sum()\n","\n","    cdf_mapping = np.zeros(256, dtype=np.uint8)\n","    j = 0\n","    for i in range(256):\n","        while ref_cdf[j] < src_cdf[i] and j < 255:\n","            j += 1\n","        cdf_mapping[i] = j\n","\n","    src_img_matched = cdf_mapping[src_img.flatten()]\n","    src_img_matched = src_img_matched.reshape(src_img.shape).astype(np.uint8)\n","\n","    return src_img_matched\n","\n","def ezmatch(src_img, ref_img):\n","    avesrc = np.mean(src_img)\n","    averef = np.mean(ref_img)\n","\n","    factor = averef/avesrc\n","    if True: #factor > 1.1 or factor < 0.9:\n","        src_img = factor*np.array(src_img)\n","        return src_img.astype(np.uint8)\n","    else:\n","        return src_img\n","\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image, ImageOps\n","from torchvision import transforms\n","import cv2\n","from skimage.feature import local_binary_pattern\n","from sklearn.model_selection import KFold\n","import json\n","\n","# clahe = False #@param{type:\"boolean\"}\n","# edgeCanny = False #@param{type:\"boolean\"}\n","# lbp = False #@param{type:\"boolean\"}\n","\n","class BasicDataset(Dataset):\n","    def __init__(self, images_dir, masks_dir,\n","                 augmentation=False, mirror=True, rotate=True,\n","                 clahe = clahe,\n","                 edgeCanny = edgeCanny,\n","                 lbp = lbp,\n","                 houghTransform = True,\n","                 surf = True):\n","        self.images_dir = images_dir\n","        self.masks_dir = masks_dir\n","        self.augmentation = augmentation\n","        self.clahe = clahe\n","        self.edgeCanny = edgeCanny\n","        self.lbp = lbp\n","        self.houghTransform = houghTransform\n","        self.surf = surf\n","\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.7, 1.3), saturation=(0.8, 1.2)),\n","        ])\n","        # self.transtensor = transforms.ToTensor()\n","\n","        self.images = [file for file in os.listdir(images_dir) if file.endswith('.png')]\n","        self.masks = [file for file in os.listdir(masks_dir) if file.endswith('.png')]\n","        # print(f'images: {len(self.images)}, masks: {len(self.masks)}')\n","\n","        if self.augmentation:\n","            self.apply_augmentation(mirror, rotate)\n","\n","    def apply_augmentation(self, mirror, rotate):\n","        for img_name in self.images:\n","            img_path = os.path.join(self.images_dir, img_name)\n","            image = Image.open(img_path).convert(\"L\")\n","\n","            if mirror:\n","                mirrored_image = ImageOps.mirror(image)\n","                mirrored_image.save(os.path.join(self.images_dir, f'mirror_{img_name}'))\n","\n","            if rotate:\n","                rotated_image = image.rotate(180)\n","                rotated_image.save(os.path.join(self.images_dir, f'rotate_{img_name}'))\n","\n","        for mask_name in self.masks:\n","            mask_path = os.path.join(self.masks_dir, mask_name)\n","            mask = Image.open(mask_path).convert(\"L\")\n","\n","            if mirror:\n","                mirrored_mask = ImageOps.mirror(mask)\n","                mirrored_mask.save(os.path.join(self.masks_dir, f'mirror_{mask_name}'))\n","\n","            if rotate:\n","                rotated_mask = mask.rotate(180)\n","                rotated_mask.save(os.path.join(self.masks_dir, f'rotate_{mask_name}'))\n","\n","        # Update the lists of images and masks after augmentation\n","        self.images = [file for file in os.listdir(self.images_dir) if file.endswith('.png')]\n","        self.masks = [file for file in os.listdir(self.masks_dir) if file.endswith('.png')]\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.images_dir, self.images[idx])\n","        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n","\n","        image = Image.open(img_path).convert(\"L\")\n","        mask = Image.open(mask_path).convert(\"L\")\n","\n","        image_np = np.array(image)\n","        image_transform = self.transform(image_np)\n","        channels = [image_transform]\n","        channels[0] = channels[0].squeeze(0).numpy()\n","\n","        if self.clahe:\n","            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","            image_clahe = clahe.apply(image_np)\n","            channels.append(image_clahe)\n","\n","        if self.edgeCanny:\n","            edges = cv2.Canny(image_np, 100, 200)\n","            channels.append(edges)\n","\n","        if self.lbp:\n","            lbp_image = local_binary_pattern(image_np, P=8, R=1, method=\"uniform\")\n","            lbp_image_normalized = cv2.normalize(lbp_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","            channels.append(lbp_image_normalized)\n","\n","        # Stack all the channels together\n","        # print(len(channels))\n","        if len(channels) > 1:\n","            # print(channels[0].shape, channels[1].shape, channels[2].shape, channels[3].shape)\n","            image_combined = np.stack(channels, axis=-1)\n","        else:\n","            image_combined = channels[0]\n","\n","        image_combined = torch.from_numpy(image_combined).float()\n","        # print(image_combined.size())\n","        if len(image_combined.size())==3:\n","            image_combined = image_combined.permute(2, 0, 1)\n","        else:\n","            image_combined = image_combined.unsqueeze(0)\n","        mask = torch.from_numpy(np.array(mask))\n","\n","        return image_combined, mask\n"]},{"cell_type":"markdown","source":["# Select and train one unet below"],"metadata":{"id":"iHOB8567GtpL"}},{"cell_type":"code","source":["#@markdown ###small original unet\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False):\n","        super().__init__()\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_classes, bilinear=False, learn = 0.005, n_channels = 4):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        # self.device = 'cpu'\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","\n","        ''' larger 1024 model\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes) '''\n","\n","        ''' smaller 512 model\n","        self.inc = DoubleConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512 )\n","        self.up1 = Up(512, 256 )\n","        self.up2 = Up(256, 128 )\n","        self.up3 = Up(128, 64)\n","        self.up4 = Up(64, 32)\n","        self.outc = OutConv(32, n_classes)#'''\n","\n","        #''' smaller 256 model\n","        self.inc = DoubleConv(n_channels, 16)\n","        self.down1 = Down(16, 32)\n","        self.down2 = Down(32, 64)\n","\n","        self.up1 = Up(64, 32 )\n","        self.up2 = Up(32, 16 )\n","\n","        self.outc = OutConv(16, n_classes)#'''\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        input = x\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","\n","        x = self.up1(x3, x2)\n","        x = self.up2(x2, x1)\n","\n","        logits = self.outc(x)\n","        return logits\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels = n_channels, n_classes = n_classes)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"],"metadata":{"cellView":"form","id":"W4KcM-OsgRQR","executionInfo":{"status":"ok","timestamp":1715035667263,"user_tz":-120,"elapsed":225,"user":{"displayName":"Xinwei Song","userId":"15192157271862011156"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"J8-Nbf6suTG0"},"outputs":[],"source":["#@markdown ###original unet\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False):\n","        super().__init__()\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_classes, bilinear=False, learn = 0.005, n_channels = 4):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        # self.device = 'cpu'\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","\n","        ''' larger 1024 model\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes) '''\n","\n","        #''' smaller 512 model\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512 )\n","        self.up1 = Up(512, 256 )\n","        self.up2 = Up(256, 128 )\n","        self.up3 = Up(128, 64)\n","        self.up4 = Up(64, 32)\n","        self.outc = OutConv(32, n_classes)#'''\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        input = x\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels = n_channels, n_classes = n_classes)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_3RrL5AmdeRP"},"outputs":[],"source":["#@markdown ### Res - attention -  unet\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class AttentionGate(nn.Module):\n","    def __init__(self, F_g, F_l, F_int):\n","        super(AttentionGate, self).__init__()\n","        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n","        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        #print(\"gate\",g.size(),'x', x.size())\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        #print(g1.size(), x1.size())\n","        diffY = x.size()[2] -g1.size()[2]\n","        diffX = x.size()[3] - g1.size()[3]\n","        g1 = F.pad(g1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","\n","        psi = self.relu(g1 + x1)\n","        psi = self.psi(psi)\n","        return x * psi\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels, res = True):\n","        super().__init__()\n","        self.res = res\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels),\n","        )\n","        self.res = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x):\n","        out = self.maxpool_conv(x)\n","        if self.res:\n","            out = self.res(out)\n","        return out\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False,\n","                 res = True):\n","        super().__init__()\n","        self.res = res\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","        self.resconv = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        out = self.conv(x)\n","        if self.res:\n","            out = self.resconv(out)\n","        return out\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False, learn = 0.0025,\n","                 resconv = True):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512)\n","\n","        self.att1 = AttentionGate(512, 256, 256)\n","        self.att2 = AttentionGate(256, 128, 128)\n","        self.att3 = AttentionGate(128, 64, 64)\n","        self.att4 = AttentionGate(64, 32, 32)\n","\n","        self.up1 = Up(512, 256, bilinear, res = resconv)\n","        self.up2 = Up(256, 128, bilinear, res = resconv)\n","        self.up3 = Up(128, 64, bilinear, res = resconv)\n","        self.up4 = Up(64, 32, bilinear)\n","\n","        self.outc = OutConv(32, n_classes)\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.8)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","\n","\n","        x4 = self.att1(x5, x4)\n","        x = self.up1(x5, x4)\n","\n","        x3 = self.att2(x, x3)\n","        x = self.up2(x, x3)\n","\n","        x2 = self.att3(x, x2)\n","        x = self.up3(x, x2)\n","\n","        x1 = self.att4(x, x1)\n","        x = self.up4(x, x1)\n","\n","        logits = self.outc(x)\n","        return logits\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels, n_classes, bilinear)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"WBHp0h3Ajvdu"},"outputs":[],"source":["#@markdown ### Res -  unet\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","\n","class AttentionGate(nn.Module):\n","    def __init__(self, F_g, F_l, F_int):\n","        super(AttentionGate, self).__init__()\n","        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n","        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        #print(\"gate\",g.size(),'x', x.size())\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        #print(g1.size(), x1.size())\n","        diffY = x.size()[2] -g1.size()[2]\n","        diffX = x.size()[3] - g1.size()[3]\n","        g1 = F.pad(g1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","\n","        psi = self.relu(g1 + x1)\n","        psi = self.psi(psi)\n","        return x * psi\n","\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels, res = True):\n","        super().__init__()\n","        self.res = res\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels),\n","        )\n","        self.res = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x):\n","        out = self.maxpool_conv(x)\n","        if self.res:\n","            out = self.res(out)\n","        return out\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False,\n","                 res = True):\n","        super().__init__()\n","        self.res = res\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","        self.resconv = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        out = self.conv(x)\n","        if self.res:\n","            out = self.resconv(out)\n","        return out\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False, learn = 0.0025,\n","                 resconv = True):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512)\n","\n","        self.att1 = AttentionGate(512, 256, 256)\n","        self.att2 = AttentionGate(256, 128, 128)\n","        self.att3 = AttentionGate(128, 64, 64)\n","        self.att4 = AttentionGate(64, 32, 32)\n","\n","        self.up1 = Up(512, 256, bilinear, res = resconv)\n","        self.up2 = Up(256, 128, bilinear, res = resconv)\n","        self.up3 = Up(128, 64, bilinear, res = resconv)\n","        self.up4 = Up(64, 32, bilinear)\n","\n","        self.outc = OutConv(32, n_classes)\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.8)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","\n","\n","        #x4 = self.att1(x5, x4)\n","        x = self.up1(x5, x4)\n","\n","        #x3 = self.att2(x, x3)\n","        x = self.up2(x, x3)\n","\n","        #x2 = self.att3(x, x2)\n","        x = self.up3(x, x2)\n","\n","        #x1 = self.att4(x, x1)\n","        x = self.up4(x, x1)\n","\n","        logits = self.outc(x)\n","        return logits\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels, n_classes, bilinear)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"II2NTdOfnQ1x"},"outputs":[],"source":["#@markdown ### att -  unet\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","\n","class AttentionGate(nn.Module):\n","    def __init__(self, F_g, F_l, F_int):\n","        super(AttentionGate, self).__init__()\n","        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n","        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        #print(\"gate\",g.size(),'x', x.size())\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        #print(g1.size(), x1.size())\n","        diffY = x.size()[2] -g1.size()[2]\n","        diffX = x.size()[3] - g1.size()[3]\n","        g1 = F.pad(g1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","\n","        psi = self.relu(g1 + x1)\n","        psi = self.psi(psi)\n","        return x * psi\n","\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels, res = False):\n","        super().__init__()\n","        self.res = res\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels),\n","        )\n","        self.resfunc = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x):\n","        out = self.maxpool_conv(x)\n","        return out\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False,\n","                 res = False):\n","        super().__init__()\n","        self.res = res\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","        self.resconv = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        out = self.conv(x)\n","        return out\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False, learn = 0.0025,\n","                 resconv = True):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512)\n","\n","        self.att1 = AttentionGate(512, 256, 256)\n","        self.att2 = AttentionGate(256, 128, 128)\n","        self.att3 = AttentionGate(128, 64, 64)\n","        self.att4 = AttentionGate(64, 32, 32)\n","\n","        self.up1 = Up(512, 256, bilinear, res = resconv)\n","        self.up2 = Up(256, 128, bilinear, res = resconv)\n","        self.up3 = Up(128, 64, bilinear, res = resconv)\n","        self.up4 = Up(64, 32, bilinear)\n","\n","        self.outc = OutConv(32, n_classes)\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.8)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","\n","\n","        x4 = self.att1(x5, x4)\n","        x = self.up1(x5, x4)\n","\n","        x3 = self.att2(x, x3)\n","        x = self.up2(x, x3)\n","\n","        x2 = self.att3(x, x2)\n","        x = self.up3(x, x2)\n","\n","        x1 = self.att4(x, x1)\n","        x = self.up4(x, x1)\n","\n","        logits = self.outc(x)\n","        return logits\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels, n_classes, bilinear)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"kUcP9c4thHK_"},"outputs":[],"source":["#@markdown ###deeps unet\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False):\n","        super().__init__()\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","def match_size(source, target):\n","    # print(f'targer:{target.size()}, source: {source.size()}')\n","    return F.interpolate(source, size=target.shape[1:], mode='bilinear', align_corners=False)\n","\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_classes=4, bilinear=False, learn = 0.005, n_channels = 1):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","\n","        ''' larger 1024 model\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes) '''\n","\n","        #''' smaller 512 model\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512 )\n","\n","        self.up1 = Up(512, 256 )\n","        self.up2 = Up(256, 128 )\n","        self.up3 = Up(128, 64)\n","        self.up4 = Up(64, 32)\n","\n","        self.out1 = OutConv(256, n_classes)\n","        self.out2 = OutConv(128, n_classes)\n","        self.out3 = OutConv(64, n_classes)\n","        self.outc = OutConv(32, n_classes)#'''\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        input = x\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        out1 = self.out1(x)\n","        x = self.up2(x, x3)\n","        out2 = self.out2(x)\n","        x = self.up3(x, x2)\n","        out3 = self.out3(x)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits, out1, out2, out3\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        inputs = F.softmax(pred_mask, dim=1)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(inputs, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(inputs, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask, out1, out2, out3 = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","        mask_loss1 = lossfunc(match_size(out1,target_mask), target_mask)\n","        mask_loss2 = lossfunc(match_size(out2,target_mask), target_mask)\n","        mask_loss3 = lossfunc(match_size(out3,target_mask), target_mask)\n","        all = mask_loss+mask_loss1+mask_loss2+mask_loss3\n","\n","        all.backward()\n","        self.optimizer.step()\n","        # print(f'mask loss:{mask_loss}, loss1{mask_loss1}, loss2{mask_loss2}, loss3:{mask_loss3}')\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask, out1, out2, out3 = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels = n_channels, n_classes = n_classes)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"]},{"cell_type":"code","source":["#@markdown ### Attention - deep - unet\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","def match_size(source, target):\n","    # print(f'targer:{target.size()}, source: {source.size()}')\n","    return F.interpolate(source, size=target.shape[1:], mode='bilinear', align_corners=False)\n","\n","class AttentionGate(nn.Module):\n","    def __init__(self, F_g, F_l, F_int):\n","        super(AttentionGate, self).__init__()\n","        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n","        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        #print(\"gate\",g.size(),'x', x.size())\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        #print(g1.size(), x1.size())\n","        diffY = x.size()[2] -g1.size()[2]\n","        diffX = x.size()[3] - g1.size()[3]\n","        g1 = F.pad(g1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","\n","        psi = self.relu(g1 + x1)\n","        psi = self.psi(psi)\n","        return x * psi\n","\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels, res = False):\n","        super().__init__()\n","        self.res = res\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels),\n","        )\n","\n","    def forward(self, x):\n","        out = self.maxpool_conv(x)\n","\n","        return out\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False,\n","                 res = False):\n","        super().__init__()\n","        self.res = res\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        out = self.conv(x)\n","\n","        return out\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False, learn = 0.0025,\n","                 resconv = True):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512)\n","\n","        self.att1 = AttentionGate(512, 256, 256)\n","        self.att2 = AttentionGate(256, 128, 128)\n","        self.att3 = AttentionGate(128, 64, 64)\n","        self.att4 = AttentionGate(64, 32, 32)\n","\n","        self.up1 = Up(512, 256, bilinear, res = resconv)\n","        self.up2 = Up(256, 128, bilinear, res = resconv)\n","        self.up3 = Up(128, 64, bilinear, res = resconv)\n","        self.up4 = Up(64, 32, bilinear)\n","\n","        self.out1 = OutConv(256, n_classes)\n","        self.out2 = OutConv(128, n_classes)\n","        self.out3 = OutConv(64, n_classes)\n","        self.outc = OutConv(32, n_classes)\n","\n","        # self.inc = inConv(n_channels, 64)\n","        # self.down1 = Down(64, 128)\n","        # self.down2 = Down(128, 256)\n","        # self.down3 = Down(256, 512)\n","        # self.down4 = Down(512, 1024)\n","\n","        # self.att1 = AttentionGate(1024, 512, 512)\n","        # self.att2 = AttentionGate(512, 256, 256)\n","        # self.att3 = AttentionGate(256, 128, 128)\n","        # self.att4 = AttentionGate(128, 64, 64)\n","\n","        # self.up1 = Up(1024, 512, bilinear, res = resconv)\n","        # self.up2 = Up(512, 256, bilinear, res = resconv)\n","        # self.up3 = Up(256, 128, bilinear, res = resconv)\n","        # self.up4 = Up(128, 64, bilinear)\n","\n","        # self.out1 = OutConv(512, n_classes)\n","        # self.out2 = OutConv(256, n_classes)\n","        # self.out3 = OutConv(128, n_classes)\n","        # self.outc = OutConv(64, n_classes)\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.8)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","\n","\n","        x4 = self.att1(x5, x4)\n","        x = self.up1(x5, x4)\n","        out1 = self.out1(x)\n","\n","        x3 = self.att2(x, x3)\n","        x = self.up2(x, x3)\n","        out2 = self.out2(x)\n","\n","        x2 = self.att3(x, x2)\n","        x = self.up3(x, x2)\n","        out3 = self.out3(x)\n","\n","        x1 = self.att4(x, x1)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits, out1, out2, out3\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self,inputs, targets, class_weights=[0.5, 1, 1.5, 1], smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        class_weights = torch.tensor(class_weights, device=inputs.device, dtype=inputs.dtype)\n","        dice_loss = (1 - dice_score) * class_weights\n","\n","        return dice_loss.mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask, out1, out2, out3 = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","        mask_loss1 = lossfunc(match_size(out1,target_mask), target_mask)\n","        mask_loss2 = lossfunc(match_size(out2,target_mask), target_mask)\n","        mask_loss3 = lossfunc(match_size(out3,target_mask), target_mask)\n","        all = mask_loss+mask_loss1+mask_loss2+mask_loss3\n","\n","        all.backward()\n","        self.optimizer.step()\n","        # print(f'mask loss:{mask_loss}, loss1{mask_loss1}, loss2{mask_loss2}, loss3:{mask_loss3}')\n","        return mask_loss.item()\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask, out1, out2, out3 = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('/content/best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels, n_classes, bilinear)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"],"metadata":{"cellView":"form","id":"Zf9A3ElOxgA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nzskg6izbgp","cellView":"form"},"outputs":[],"source":["#@markdown ### Res - attention - deep - unet\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","def match_size(source, target):\n","    # print(f'targer:{target.size()}, source: {source.size()}')\n","    return F.interpolate(source, size=target.shape[1:], mode='bilinear', align_corners=False)\n","\n","class AttentionGate(nn.Module):\n","    def __init__(self, F_g, F_l, F_int):\n","        super(AttentionGate, self).__init__()\n","        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n","        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, g, x):\n","        #print(\"gate\",g.size(),'x', x.size())\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        #print(g1.size(), x1.size())\n","        diffY = x.size()[2] -g1.size()[2]\n","        diffX = x.size()[3] - g1.size()[3]\n","        g1 = F.pad(g1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","\n","        psi = self.relu(g1 + x1)\n","        psi = self.psi(psi)\n","        return x * psi\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels, res = True):\n","        super().__init__()\n","        self.res = res\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels),\n","        )\n","        self.res = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x):\n","        out = self.maxpool_conv(x)\n","        if self.res:\n","            out = self.res(out)\n","        return out\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False,\n","                 res = False):\n","        super().__init__()\n","        self.res = res\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","        self.resconv = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        out = self.conv(x)\n","        if self.res:\n","            out = self.resconv(out)\n","        return out\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False, learn = 0.0025,\n","                 resconv = True):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512)\n","\n","        self.att1 = AttentionGate(512, 256, 256)\n","        self.att2 = AttentionGate(256, 128, 128)\n","        self.att3 = AttentionGate(128, 64, 64)\n","        self.att4 = AttentionGate(64, 32, 32)\n","\n","        self.up1 = Up(512, 256, bilinear, res = resconv)\n","        self.up2 = Up(256, 128, bilinear, res = resconv)\n","        self.up3 = Up(128, 64, bilinear, res = resconv)\n","        self.up4 = Up(64, 32, bilinear)\n","\n","        self.out1 = OutConv(256, n_classes)\n","        self.out2 = OutConv(128, n_classes)\n","        self.out3 = OutConv(64, n_classes)\n","        self.outc = OutConv(32, n_classes)\n","\n","        # self.inc = inConv(n_channels, 64)\n","        # self.down1 = Down(64, 128)\n","        # self.down2 = Down(128, 256)\n","        # self.down3 = Down(256, 512)\n","        # self.down4 = Down(512, 1024)\n","\n","        # self.att1 = AttentionGate(1024, 512, 512)\n","        # self.att2 = AttentionGate(512, 256, 256)\n","        # self.att3 = AttentionGate(256, 128, 128)\n","        # self.att4 = AttentionGate(128, 64, 64)\n","\n","        # self.up1 = Up(1024, 512, bilinear, res = resconv)\n","        # self.up2 = Up(512, 256, bilinear, res = resconv)\n","        # self.up3 = Up(256, 128, bilinear, res = resconv)\n","        # self.up4 = Up(128, 64, bilinear)\n","\n","        # self.out1 = OutConv(512, n_classes)\n","        # self.out2 = OutConv(256, n_classes)\n","        # self.out3 = OutConv(128, n_classes)\n","        # self.outc = OutConv(64, n_classes)\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.8)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        coveg=x2\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        pooleg=x5\n","\n","        x4 = self.att1(x5, x4)\n","        x = self.up1(x5, x4)\n","        out1 = self.out1(x)\n","\n","        x3 = self.att2(x, x3)\n","        x = self.up2(x, x3)\n","        out2 = self.out2(x)\n","\n","        x2 = self.att3(x, x2)\n","        x = self.up3(x, x2)\n","        out3 = self.out3(x)\n","\n","        x1 = self.att4(x, x1)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits, out1, out2, out3,coveg,pooleg\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self,inputs, targets, class_weights=[0.5, 1, 1.5, 1], smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        class_weights = torch.tensor(class_weights, device=inputs.device, dtype=inputs.dtype)\n","        dice_loss = (1 - dice_score) * class_weights\n","\n","        return dice_loss.mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask, out1, out2, out3, coveg,pooleg = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","        mask_loss1 = lossfunc(match_size(out1,target_mask), target_mask)\n","        mask_loss2 = lossfunc(match_size(out2,target_mask), target_mask)\n","        mask_loss3 = lossfunc(match_size(out3,target_mask), target_mask)\n","        all = mask_loss+mask_loss1+mask_loss2+mask_loss3\n","\n","        all.backward()\n","        self.optimizer.step()\n","        # print(f'mask loss:{mask_loss}, loss1{mask_loss1}, loss2{mask_loss2}, loss3:{mask_loss3}')\n","        return mask_loss.item()\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask, out1, out2, out3, coveg,pooleg = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('./content/best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            print(preds.size())\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels, n_classes, bilinear)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"]},{"cell_type":"code","source":["#@markdown ### Res - deep - unet\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","def match_size(source, target):\n","    # print(f'targer:{target.size()}, source: {source.size()}')\n","    return F.interpolate(source, size=target.shape[1:], mode='bilinear', align_corners=False)\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        residual = self.shortcut(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        out = self.double_conv(x)\n","\n","        return out\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels, res = True):\n","        super().__init__()\n","        self.res = res\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels),\n","        )\n","        self.res = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x):\n","        out = self.maxpool_conv(x)\n","        if self.res:\n","            out = self.res(out)\n","        return out\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False,\n","                 res = False):\n","        super().__init__()\n","        self.res = res\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","        self.resconv = ResidualBlock(out_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        out = self.conv(x)\n","        if self.res:\n","            out = self.resconv(out)\n","        return out\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False, learn = 0.0025,\n","                 resconv = True):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512)\n","\n","        self.up1 = Up(512, 256, bilinear, res = resconv)\n","        self.up2 = Up(256, 128, bilinear, res = resconv)\n","        self.up3 = Up(128, 64, bilinear, res = resconv)\n","        self.up4 = Up(64, 32, bilinear)\n","\n","        self.out1 = OutConv(256, n_classes)\n","        self.out2 = OutConv(128, n_classes)\n","        self.out3 = OutConv(64, n_classes)\n","        self.outc = OutConv(32, n_classes)\n","\n","        # self.inc = inConv(n_channels, 64)\n","        # self.down1 = Down(64, 128)\n","        # self.down2 = Down(128, 256)\n","        # self.down3 = Down(256, 512)\n","        # self.down4 = Down(512, 1024)\n","\n","        # self.att1 = AttentionGate(1024, 512, 512)\n","        # self.att2 = AttentionGate(512, 256, 256)\n","        # self.att3 = AttentionGate(256, 128, 128)\n","        # self.att4 = AttentionGate(128, 64, 64)\n","\n","        # self.up1 = Up(1024, 512, bilinear, res = resconv)\n","        # self.up2 = Up(512, 256, bilinear, res = resconv)\n","        # self.up3 = Up(256, 128, bilinear, res = resconv)\n","        # self.up4 = Up(128, 64, bilinear)\n","\n","        # self.out1 = OutConv(512, n_classes)\n","        # self.out2 = OutConv(256, n_classes)\n","        # self.out3 = OutConv(128, n_classes)\n","        # self.outc = OutConv(64, n_classes)\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.8)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        coveg=x2\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        pooleg=x5\n","\n","        x = self.up1(x5, x4)\n","        out1 = self.out1(x)\n","\n","        x = self.up2(x, x3)\n","        out2 = self.out2(x)\n","\n","        x = self.up3(x, x2)\n","        out3 = self.out3(x)\n","\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits, out1, out2, out3,coveg,pooleg\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(pred_mask, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(pred_mask, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self,inputs, targets, class_weights=[0.5, 1, 1.5, 1], smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        class_weights = torch.tensor(class_weights, device=inputs.device, dtype=inputs.dtype)\n","        dice_loss = (1 - dice_score) * class_weights\n","\n","        return dice_loss.mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask, out1, out2, out3, coveg,pooleg = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","        mask_loss1 = lossfunc(match_size(out1,target_mask), target_mask)\n","        mask_loss2 = lossfunc(match_size(out2,target_mask), target_mask)\n","        mask_loss3 = lossfunc(match_size(out3,target_mask), target_mask)\n","        all = mask_loss+mask_loss1+mask_loss2+mask_loss3\n","\n","        all.backward()\n","        self.optimizer.step()\n","        # print(f'mask loss:{mask_loss}, loss1{mask_loss1}, loss2{mask_loss2}, loss3:{mask_loss3}')\n","        return mask_loss.item()\n","\n","        mask_loss.backward()\n","        self.optimizer.step()\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask, out1, out2, out3, coveg,pooleg = self(inputs)\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('./content/best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            print(preds.size())\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels, n_classes, bilinear)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"],"metadata":{"cellView":"form","id":"iV5Gp2Jav-Os"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ###new deeps unet\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import cv2\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels, bilinear=False):\n","        super().__init__()\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","def match_size(source, target):\n","    # print(f'targer:{target.size()}, source: {source.size()}')\n","    return F.interpolate(source, size=target.shape[1:], mode='bilinear', align_corners=False)\n","\n","class inConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=7, padding=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_classes=4, bilinear=False, learn = 0.005, n_channels = 1):\n","        if torch.cuda.is_available():\n","            self.device = torch.device('cuda')\n","        elif torch.backends.mps.is_available():\n","            self.device = torch.device('mps')\n","        else:\n","            self.device = torch.device('cpu')\n","\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","\n","        ''' larger 1024 model\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes) '''\n","\n","        #''' smaller 512 model\n","        self.inc = inConv(n_channels, 32)\n","        self.down1 = Down(32, 64)\n","        self.down2 = Down(64, 128)\n","        self.down3 = Down(128, 256)\n","        self.down4 = Down(256, 512 )\n","\n","        self.up1 = Up(512, 256 )\n","        self.up2 = Up(256, 128 )\n","        self.up3 = Up(128, 64)\n","        self.up4 = Up(64, 32)\n","\n","        self.out11 = OutConv(64, n_classes)\n","        self.out22 = OutConv(128, n_classes)\n","        self.out33 = OutConv(256, n_classes)\n","        self.out44 = OutConv(512, n_classes)\n","\n","        self.out1 = OutConv(256, n_classes)\n","        self.out2 = OutConv(128, n_classes)\n","        self.out3 = OutConv(64, n_classes)\n","        self.outc = OutConv(32, n_classes)#'''\n","\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr=learn)\n","\n","        self.history = {\"train_loss\": [], \"val_loss\": []}\n","\n","    def forward(self, x):\n","        input = x\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        out11 = self.out11(x2)\n","\n","        x3 = self.down2(x2)\n","        out22 = self.out22(x3)\n","\n","        x4 = self.down3(x3)\n","        out33 = self.out33(x4)\n","\n","        x5 = self.down4(x4)\n","        out44 = self.out44(x5)\n","\n","        x = self.up1(x5, x4)\n","        out1 = self.out1(x)\n","\n","        x = self.up2(x, x3)\n","        out2 = self.out2(x)\n","\n","        x = self.up3(x, x2)\n","        out3 = self.out3(x)\n","\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits, out1, out2, out3,out11,out22,out33,out44\n","\n","    def ce_loss(self, pred_mask, target_mask, weighted=False):\n","        target_mask = target_mask.squeeze(1).type(torch.long)\n","        inputs = F.softmax(pred_mask, dim=1)\n","        if weighted:\n","            weight = torch.ones(pred_mask.shape[1], device=self.device)\n","            weight[0] = 10\n","            weight[1] = 10\n","            weight[2] = 10\n","            loss = F.cross_entropy(inputs, target_mask, weight=weight)\n","        else:\n","            loss = F.cross_entropy(inputs, target_mask)\n","        return loss\n","\n","    def focal_loss(self, inputs, targets, alpha=0.25, gamma=2.0, epsilon=1e-9):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)  # [batch_size, 1, height, width] to [batch_size, height, width]\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        inputs = inputs.clamp(min=epsilon, max=1.0 - epsilon)\n","        pt = torch.where(torch.eq(targets, 1), inputs, 1 - inputs)\n","        loss = -alpha * (1 - pt) ** gamma * torch.log(pt)\n","\n","        return loss.mean()\n","\n","    def dice_loss(self, inputs, targets, smooth=1e-6):\n","        inputs = F.softmax(inputs, dim=1)\n","        targets = targets.squeeze(1)\n","        targets = F.one_hot(targets, num_classes=inputs.shape[1]).permute(0, 3, 1, 2).float()\n","\n","        intersection = 2.0 * (inputs * targets).sum(dim=(2, 3))\n","        union = inputs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n","        dice_score = (intersection + smooth) / (union + smooth)\n","\n","        return (1 - dice_score).mean()\n","\n","    def combined_loss(self, inputs, targets, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n","        loss_focal = self.focal_loss(inputs, targets, alpha=alpha, gamma=gamma)\n","        loss_dice = self.dice_loss(inputs, targets, smooth=smooth)\n","        return beta * loss_focal + (1 - beta) * loss_dice\n","\n","\n","    def train_step(self, inputs, target_mask, lossfunc):\n","        inputs, target_mask = inputs.to(self.device), target_mask.to(self.device)\n","        self.train()\n","        self.optimizer.zero_grad()\n","        pred_mask, out1, out2, out3,out11,out22,out33,out44 = self(inputs)\n","        mask_loss = lossfunc(pred_mask, target_mask)\n","        mask_loss1 = lossfunc(match_size(out1,target_mask), target_mask)\n","        mask_loss2 = lossfunc(match_size(out2,target_mask), target_mask)\n","        mask_loss3 = lossfunc(match_size(out3,target_mask), target_mask)\n","\n","        mask_loss4 = lossfunc(match_size(out11,target_mask), target_mask)\n","        mask_loss5 = lossfunc(match_size(out22,target_mask), target_mask)\n","        mask_loss6 = lossfunc(match_size(out33,target_mask), target_mask)\n","        mask_loss7 = lossfunc(match_size(out44,target_mask), target_mask)\n","\n","        loss_encoder = mask_loss4+mask_loss5+mask_loss6+mask_loss7\n","        loss_decoder = mask_loss1+mask_loss2+mask_loss3\n","\n","        all = 0.5*loss_encoder+loss_decoder+mask_loss\n","\n","        all.backward()\n","        self.optimizer.step()\n","        # print(f'mask loss:{mask_loss}, loss1{mask_loss1}, loss2{mask_loss2}, loss3:{mask_loss3}')\n","        return mask_loss.item()\n","\n","    def validate(self, val_loader, lossfunc):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, target_mask in val_loader:\n","                target_mask = target_mask.long()\n","                inputs, target_mask = inputs.to(device), target_mask.to(device)\n","                pred_mask = self(inputs)[0]\n","                mask_loss = lossfunc(pred_mask, target_mask)\n","\n","                total_loss += mask_loss.item()\n","        return total_loss / len(val_loader)\n","\n","    def train_model(self, train_loader, epochs, batch_size, val_loader= None, loss='dice_loss', best_loss = 10):\n","        alloss = {'dice_loss': self.dice_loss, 'focal_loss': self.focal_loss,\n","                  'combined_loss': self.combined_loss, 'ce_loss': self.ce_loss}\n","        lossfunc = alloss[loss]\n","\n","        for epoch in range(epochs):\n","            start_time = time.time()\n","\n","            # n_val = int(len(full_dataset) * val_percent)\n","            # n_train = len(full_dataset) - n_val\n","            # train_subset, val_subset = torch.utils.data.random_split(full_dataset, [n_train, n_val])\n","\n","            # train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","            # val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size)\n","\n","            total_train_loss = 0\n","            for inputs, target_mask in train_loader:\n","                target_mask = target_mask.long()\n","                mask_loss = self.train_step(inputs, target_mask, lossfunc)\n","                total_train_loss += mask_loss\n","            avg_train_loss = total_train_loss / len(train_loader)\n","            self.history[\"train_loss\"].append(avg_train_loss)\n","\n","            end_time = time.time()\n","            elapsed_time = end_time - start_time\n","\n","            if val_loader:\n","                avg_val_loss = self.validate(val_loader, lossfunc)\n","                self.history[\"val_loss\"].append(avg_val_loss)\n","            else:\n","                avg_val_loss = 0\n","            all_loss = avg_val_loss+avg_train_loss\n","            if all_loss<best_loss:\n","                best_loss = all_loss\n","                self.save_model('best_unet.pth')\n","                print(f'best model update: {best_loss}')\n","\n","            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss} Time: {elapsed_time:.2f} sec\")\n","\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","\n","    def predict(self, x):\n","        x = x.to(self.device)\n","        self.eval()\n","        with torch.no_grad():\n","            preds = self(x)\n","            preds = preds.argmax(dim=1)  #  (batch_size, height, width)\n","\n","            preds = preds.float() / (self.n_classes - 1) * 255\n","            preds = preds.to(torch.uint8)\n","\n","            return preds\n","\n","    def save_model(self, file_path):\n","        torch.save(self.state_dict(), file_path)\n","\n","    @staticmethod\n","    def load_model(file_path, n_channels, n_classes, bilinear=False):\n","        model = UNet(n_channels = n_channels, n_classes = n_classes)\n","        model.load_state_dict(torch.load(file_path, map_location=model.device))\n","        return model\n"],"metadata":{"cellView":"form","id":"_lnZ7ReEWU5p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train and test"],"metadata":{"id":"9foxopXjG1gb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuaUpCowEvnf","cellView":"form"},"outputs":[],"source":["#@markdown ### train\n","from torch.utils.data import DataLoader, random_split\n","from IPython.display import clear_output\n","from glob import glob\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","\n","train_x = './data/imgs'#@param{type:\"string\"}\n","train_y = './data/masks'#@param{type:\"string\"}\n","num_class = 4 #@param{type:\"number\"}\n","batch_size = 1 #@param{type:\"number\"}\n","# validation_percent = 0.15 #@param{type:\"number\"}\n","validation_percent = 0.15\n","epoch = 50 #@param{type:\"number\"}\n","learning_rate = 0.0001 #@param{type:\"number\"}\n","# augmentation = False #@param{type:\"boolean\"}\n","loss_function =  'ce_loss' # @param ['combined_loss', \"dice_loss\", \"focal_loss\", \"ce_loss\"]\n","test_percent = 0 #@param{type:\"number\"}\n","inchannel = 1 #@param{type:\"number\"}\n","test_image_dir = '/content/test/imgs' #@param{type:\"string\"}\n","test_mask_dir = '/content/test/masks' #@param{type:\"string\"}\n","show_images = False #@param{type:\"boolean\"}\n","train_type = 'whole dataset' # @param ['5-fold validation', 'whole dataset']\n","\n","base_path = '/content/'\n","if not os.path.isdir(f\"{base_path}test/\"):\n","    seed(42)\n","    os.makedirs(f\"{base_path}test/imgs\", exist_ok=True)\n","    os.makedirs(f\"{base_path}test/masks\", exist_ok=True)\n","\n","    file_names = [file for file in os.listdir(train_x) if file.endswith('.png')]\n","    num_files_to_select = round(len(file_names) * test_percent)\n","    selected_files = sample(file_names, num_files_to_select)\n","    for file_name in selected_files:\n","        shutil.move(f\"{train_x}/{file_name}\", f\"{base_path}test/imgs/{file_name}\")\n","        shutil.move(f\"{train_y}/{file_name}\", f\"{base_path}test/masks/{file_name}\")\n","\n","\n","def visualize_predictions(loader,model,\n","                          contrast = None,\n","                          destination = 'output'):\n","    # ref_img = np.array(Image.open('./content/test/imgs/frame50_19.png').convert(\"L\"))\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","    ]) #        transforms.Resize((256, 256)),\n","    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda')\n","    elif torch.backends.mps.is_available():\n","        device = torch.device('mps')\n","    else:\n","        device = torch.device('cpu')\n","\n","    dices = 0\n","    ious = 0\n","    num = 0\n","\n","    total_confusion_matrix = np.zeros((num_class, num_class))\n","    for inputs, target_mask in tqdm(loader):\n","        num+=1\n","        image_np = np.array(inputs)\n","        image_np = image_np[0,0,:,:]\n","\n","        image_transform = transform(image_np)\n","        channels = [image_transform]\n","        channels[0] = channels[0].squeeze(0).numpy()\n","\n","        if len(channels) > 1:\n","            # print(channels[0].shape, channels[1].shape, channels[2].shape, channels[3].shape)\n","            image_combined = np.stack(channels, axis=-1)\n","        else:\n","            image_combined = channels[0]\n","\n","        image_combined = torch.from_numpy(image_combined).float().to(device)\n","        if len(image_combined.size())==3:\n","            image_combined = image_combined.permute(2, 0, 1)\n","        else:\n","            image_combined = image_combined.unsqueeze(0)\n","        image_combined = image_combined.unsqueeze(0).to(device)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            prediction = model(image_combined)\n","            if len(prediction) > 1:\n","                prediction = prediction[0]\n","            prediction = prediction.argmax(dim=1).squeeze(0).cpu().numpy()\n","\n","        mask = np.array(target_mask)\n","\n","        prediction_flat = prediction.flatten()\n","        mask_flat = np.array(mask).flatten()\n","        cm = confusion_matrix(mask_flat, prediction_flat, labels=[0, 1, 2, 3]) #4\n","        total_confusion_matrix += cm\n","        accuracy = np.trace(cm) / np.sum(cm)\n","\n","    np.set_printoptions(suppress=True, precision=0, formatter={'float': '{:0.0f}'.format})\n","\n","\n","    accuracy = np.trace(total_confusion_matrix) / np.sum(total_confusion_matrix)\n","    labels = ['Label 0', 'Label 1', 'Label 2', 'Label 3'] #, 'Label 4'\n","    cm_df = pd.DataFrame(total_confusion_matrix, index=[f'True {label}' for label in labels],\n","                     columns=[f'Pre {label}' for label in labels])\n","\n","    precisions = []\n","    recalls = []\n","    class_accuracies = []\n","    class_dice_scores = []\n","    class_iou_scores = []\n","\n","    for i in range(len(labels)):\n","        TP = total_confusion_matrix[i, i]\n","        FP = np.sum(total_confusion_matrix[:, i]) - TP\n","        FN = np.sum(total_confusion_matrix[i, :]) - TP\n","        TN = np.sum(total_confusion_matrix) - TP - FP - FN  # DiceIOU\n","\n","        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n","        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n","        class_accuracy = TP / (TP + FN) if (TP + FN) > 0 else 0  # \n","\n","        dice_score = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n","        iou_score = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n","\n","        precisions.append(precision)\n","        recalls.append(recall)\n","        class_accuracies.append(class_accuracy)\n","        class_dice_scores.append(dice_score)\n","        class_iou_scores.append(iou_score)\n","\n","    overall_accuracy = np.trace(total_confusion_matrix) / np.sum(total_confusion_matrix)\n","\n","    print(\"Confusion Matrix:\")\n","    print(cm_df)\n","\n","    return sum(class_dice_scores)/len(labels), sum(class_iou_scores)/len(labels), sum(precisions)/len(labels), sum(recalls)/len(labels)\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","elif torch.backends.mps.is_available():\n","    device = torch.device('mps')\n","else:\n","    device = torch.device('cpu')\n","# device = 'cpu'\n","\n","import shutil\n","from random import sample, seed\n","\n","train_dataset = BasicDataset(images_dir=train_x, masks_dir=train_y, augmentation=False)\n","test_dataset = BasicDataset(images_dir=test_image_dir, masks_dir = test_mask_dir)\n","\n","def test():\n","    verboses = ''\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    start_time = time.time()\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    model = UNet(n_classes=num_class, learn = learning_rate, n_channels = inchannel).to(device)\n","    model.train_model(train_loader = train_loader,\n","                      epochs = epoch, batch_size = batch_size,\n","                      loss = loss_function,\n","                      best_loss = 10) #combined_loss, focal_loss, dice_loss, ce_loss\n","    history = model.history\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(f'time spend: {elapsed_time:.4f}s')\n","    model.save_model(f'{base_path}final_unet.pth')\n","    dice, iou, precision, recall = visualize_predictions(test_loader, model)\n","    verbose = f'{dice} {iou} {precision} {recall}\\n'\n","    print(verbose)\n","\n","\n","def kfold():\n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    fold_results = []\n","    initial_loss = 10\n","    dicess, iouss,precisionss, recallss = [],[],[],[]\n","    for fold, (train_index, val_index) in enumerate(kf.split(train_dataset)):\n","        train_subset = torch.utils.data.Subset(train_dataset, train_index)\n","        val_subset = torch.utils.data.Subset(train_dataset, val_index)\n","\n","        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","        val_loader = DataLoader(val_subset, batch_size=batch_size)\n","\n","        model = UNet(n_classes=num_class, learn = learning_rate, n_channels = inchannel).to(device)\n","\n","        start_time = time.time()\n","        model.train_model(train_loader = train_loader,\n","                          val_loader = val_loader,\n","                          epochs = epoch, batch_size = batch_size,\n","                          val_percent = validation_percent,\n","                          loss = loss_function,\n","                          best_loss = initial_loss) #combined_loss, focal_loss, dice_loss, ce_loss\n","        history = model.history\n","        fold_results.append(history)\n","        total_losses = [train + val for train, val in zip(history['train_loss'], history['val_loss'])]\n","        min_total_loss = min(total_losses)\n","        min_total_loss_index = total_losses.index(min_total_loss) + 1\n","        if fold == 0:\n","            print(fold)\n","            initial_loss = min_total_loss\n","        elif min_total_loss<initial_loss:\n","            initial_loss = min_total_loss\n","\n","        end_time = time.time()\n","        elapsed_time = end_time - start_time\n","        print(f'time spend: {elapsed_time:.4f}s')\n","        model.save_model('./content/final_unet.pth')\n","        unetmodel = UNet.load_model('./content/final_unet.pth', n_channels=1, n_classes=4)\n","        unetmodel = unetmodel.to(device)\n","        dice, iou, precision, recall = visualize_predictions(val_loader,unetmodel)\n","        unetmodel.save_model(f'./models/newds/{dice:.4f}{iou:.4f}final_unet.pth')\n","        dicess.append(dice)\n","        iouss.append(iou)\n","        precisionss.append(precision)\n","        recallss.append(recall)\n","\n","        half = False\n","        if half:\n","            model_half = model.half()\n","            torch.save(model_half.state_dict(), \"unet_model_float16.pth\")\n","            # model_half.load_state_dict(torch.load(\"unet_model_float16.pth\"))\n","    print(f'{sum(dicess)/len(dicess):.4f}, {sum(iouss)/len(iouss):.4f},{sum(precisionss)/len(precisionss):.4f}, {sum(recallss)/len(recallss):.4f}')\n","\n","if train_type == 'whole dataset':\n","    test()\n","elif train_type == '5-fold validation':\n","    kfold()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"KXK8mvjJ4mix","colab":{"base_uri":"https://localhost:8080/","height":562},"executionInfo":{"status":"ok","timestamp":1714114652096,"user_tz":-120,"elapsed":329,"user":{"displayName":"Xinwei Song","userId":"15192157271862011156"}},"outputId":"f83700f8-a1ee-4c72-82ae-35e1c8601486"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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"},"metadata":{}}],"source":["#@markdown ### los curve\n","show_curve = True #@param{type:\"boolean\"}\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","json_file_path = './content/training_history.json'\n","with open(json_file_path, 'w') as file:\n","    json.dump(fold_results, file, indent=4)\n","\n","rows = []\n","for item in fold_results:\n","    for train_loss, val_loss in zip(item['train_loss'], item['val_loss']):\n","        rows.append({'train_loss': train_loss, 'val_loss': val_loss})\n","\n","df = pd.DataFrame(rows)\n","csv_file_path = './content/training_history.csv'\n","df.to_csv(csv_file_path, index=True)\n","\n","train_losses = np.array([fold['train_loss'] for fold in fold_results])\n","val_losses = np.array([fold['val_loss'] for fold in fold_results])\n","\n","train_loss_mean = np.mean(train_losses, axis=0)\n","val_loss_mean = np.mean(val_losses, axis=0)\n","train_loss_std = np.std(train_losses, axis=0)\n","val_loss_std = np.std(val_losses, axis=0)\n","\n","plt.figure(figsize=(10, 6))\n","epochs_range = np.arange(1, len(train_loss_mean) + 1)\n","\n","plt.plot(epochs_range, train_loss_mean, label='Average Train Loss', color='blue')\n","plt.fill_between(epochs_range, train_loss_mean - train_loss_std, train_loss_mean + train_loss_std, color='blue', alpha=0.2)\n","\n","plt.plot(epochs_range, val_loss_mean, label='Average Validation Loss', linestyle='--', color='blue')\n","plt.fill_between(epochs_range, val_loss_mean - val_loss_std, val_loss_mean + val_loss_std, color='blue', alpha=0.2)\n","\n","plt.title('Average Training and Validation Loss with SD')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","if show_curve:\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBOGNM_rVTkU","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1v52NjGDGfJUuzavi4H6DF4vHkNuqWeMZ"},"executionInfo":{"status":"ok","timestamp":1714438506999,"user_tz":-120,"elapsed":7897,"user":{"displayName":"Xinwei Song","userId":"15192157271862011156"}},"outputId":"66a89d52-dac9-40f5-cf1e-9afa5c33f80d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@markdown ### eval\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","elif torch.backends.mps.is_available():\n","    device = torch.device('mps')\n","else:\n","    device = torch.device('cpu')\n","\n","model = 'best_unet.pth' # @param ['final_unet.pth', 'best_unet.pth']\n","\n","num_class = 4\n","unetmodel = UNet.load_model(model, n_channels=1, n_classes=num_class)\n","unetmodel = unetmodel.to(device)\n","\n","import os\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from torchvision import transforms\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from csbdeep.utils import normalize\n","\n","doclahe = False #@param{type:\"boolean\"}\n","edgeCanny = False #@param{type:\"boolean\"}\n","lbp = False #@param{type:\"boolean\"}\n","contrast_stratergy = 'none' # @param ['linear', \"cdf\", \"none\"]\n","save_path = './content/output' #@param{type:\"string\"}\n","def calculate_dice_multi_class(prediction, mask, num_classes):\n","    dice_scores = []\n","    for class_index in range(1, num_classes): #ex background\n","        pred_bin = (prediction == class_index).astype(np.float32)\n","        mask_bin = (mask == class_index).astype(np.float32)\n","\n","        intersection = np.sum(pred_bin * mask_bin)\n","        total = np.sum(pred_bin) + np.sum(mask_bin)\n","        if total == 0:\n","            dice_scores.append(1.0)\n","        else:\n","            dice_scores.append(2.0 * intersection / total)\n","\n","    return np.mean(dice_scores)\n","\n","def calculate_iou(prediction, mask):\n","    intersection = np.logical_and(prediction, mask)\n","    union = np.logical_or(prediction, mask)\n","    iou = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 1\n","    return iou\n","\n","def visualize_predictions(image_dir, mask_dir, model,show,\n","                          contrast = contrast_stratergy,\n","                          destination = save_path):\n","    ref_img = np.array(Image.open('./content/test/imgs/frame50_19.png').convert(\"L\"))\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","    ]) #        transforms.Resize((256, 256)),\n","    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda')\n","    elif torch.backends.mps.is_available():\n","        device = torch.device('mps')\n","    else:\n","        device = torch.device('cpu')\n","\n","    dices = 0\n","    ious = 0\n","    num = 0\n","\n","    total_confusion_matrix = np.zeros((num_class, num_class))\n","    for filename in tqdm(os.listdir(image_dir)):\n","        if filename.endswith('.png'):\n","            num+=1\n","            image_path = os.path.join(image_dir, filename)\n","            mask_path = os.path.join(mask_dir, filename)\n","\n","            image = Image.open(image_path).convert('L')\n","            mask = Image.open(mask_path).convert('L')\n","\n","            image_np = np.array(image)\n","            if contrast == 'linear':\n","                image_np = ezmatch(image_np, ref_img)\n","            elif contrast == 'cdf':\n","                image_np = match_histograms(image_np, ref_img) #match_histograms\n","\n","            # img_normalized = normalize(image_np, 0.0001, 99.9999, axis=(0,1))\n","\n","            image_transform = transform(image_np)\n","            channels = [image_transform]\n","            channels[0] = channels[0].squeeze(0).numpy()\n","\n","            if doclahe:\n","                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","                image_clahe = clahe.apply(image_np)\n","                channels.append(image_clahe)\n","\n","            if edgeCanny:\n","                edges = cv2.Canny(image_np, 100, 200)\n","                channels.append(edges)\n","\n","            if lbp:\n","                lbp_image = local_binary_pattern(image_np, P=8, R=1, method=\"uniform\")\n","                lbp_image_normalized = cv2.normalize(lbp_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","                channels.append(lbp_image_normalized)\n","\n","            if len(channels) > 1:\n","                # print(channels[0].shape, channels[1].shape, channels[2].shape, channels[3].shape)\n","                image_combined = np.stack(channels, axis=-1)\n","            else:\n","                image_combined = channels[0]\n","\n","            image_combined = torch.from_numpy(image_combined).float()\n","            if len(image_combined.size())==3:\n","                image_combined = image_combined.permute(2, 0, 1)\n","            else:\n","                image_combined = image_combined.unsqueeze(0)\n","            image_combined = image_combined.unsqueeze(0).to(device)\n","\n","            model.eval()\n","            with torch.no_grad():\n","                prediction = model(image_combined)\n","                if len(prediction) > 1:\n","                    prediction = prediction[0]\n","                prediction = prediction.argmax(dim=1).squeeze(0).cpu().numpy()\n","                # coveg = coveg[0, 0, :, :]\n","                # pooleg = pooleg[0, 0, :, :]\n","\n","            dice_score = calculate_dice_multi_class(prediction, np.array(mask), 5)\n","            iou_score = calculate_iou(prediction, np.array(mask))\n","            image = np.array(image)\n","            mask = np.array(mask)\n","\n","            # mask = (255 * (mask - np.min(mask)) / np.ptp(mask)).astype(np.uint8)\n","            img = Image.fromarray(prediction.astype(np.uint8))\n","            img.save(f\"{destination}/{filename}\")\n","\n","            # coveg = Image.fromarray(coveg.cpu().numpy().astype(np.uint8))\n","            # img.save(f\"{destination}/coveg_{filename}\")\n","\n","            # pooleg = Image.fromarray(pooleg.cpu().numpy().astype(np.uint8))\n","            # img.save(f\"{destination}/pooleg_{filename}\")\n","\n","            if show:\n","                fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n","\n","                axes[0].imshow(image_np, cmap='gray')\n","                axes[0].set_title(f'Original Image {filename}')\n","                axes[0].axis('off')\n","\n","                axes[1].imshow(np.array(mask), cmap='CMRmap_r', vmin=0, vmax=num_class)\n","                axes[1].set_title('Ground Truth')\n","                axes[1].axis('off')\n","\n","                axes[2].imshow(prediction, cmap='CMRmap_r', vmin=0, vmax=num_class)\n","                axes[2].set_title('Predicted Image')\n","                axes[2].axis('off')\n","\n","                axes[3].imshow(mask, cmap='CMRmap_r', alpha=0.5, vmin=0, vmax=num_class)\n","                axes[3].imshow(prediction, cmap='CMRmap_r', alpha=0.5, vmin=0, vmax=num_class)\n","                axes[3].set_title('Overlap')\n","                axes[3].axis('off')\n","\n","                plt.show()\n","            dices += dice_score\n","            ious += iou_score\n","            # print(f\"Dice Score: {dice_score:.4f}, IOU Score: {iou_score:.4f}\")\n","\n","            prediction_flat = prediction.flatten()\n","            mask_flat = np.array(mask).flatten()\n","            cm = confusion_matrix(mask_flat, prediction_flat, labels=[0, 1, 2, 3]) #4\n","            total_confusion_matrix += cm\n","            accuracy = np.trace(cm) / np.sum(cm)\n","\n","            # print('acc',accuracy, 'dic', dice_score, 'iou',iou_score)\n","\n","    np.set_printoptions(suppress=True, precision=0, formatter={'float': '{:0.0f}'.format})\n","\n","    # if show:\n","    #     plt.figure(figsize=(10, 8))\n","    #     sns.heatmap(total_confusion_matrix, annot=True, fmt='g', cmap='Blues')\n","    #     plt.xlabel('Predicted labels')\n","    #     plt.ylabel('True labels')\n","    #     plt.title('Confusion Matrix')\n","    #     plt.savefig('./confusion_matrix.pdf')\n","    #     plt.show()\n","\n","    accuracy = np.trace(total_confusion_matrix) / np.sum(total_confusion_matrix)\n","    labels = ['Label 0', 'Label 1', 'Label 2', 'Label 3'] #, 'Label 4'\n","    cm_df = pd.DataFrame(total_confusion_matrix, index=[f'True {label}' for label in labels],\n","                     columns=[f'Pre {label}' for label in labels])\n","    print(\"Confusion Matrix:\")\n","    print(cm_df)\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Avg Dice Score: {dices/num:.4f}, Avg IOU Score: {ious/num:.4f}\")\n","\n","\n","image_dir = './content/test/imgs' #@param{type:\"string\"}\n","mask_dir = './content/test/masks' #@param{type:\"string\"}\n","show_images = False #@param{type:\"boolean\"}\n","\n","visualize_predictions(image_dir, mask_dir, unetmodel,show_images)"]},{"cell_type":"code","execution_count":16,"metadata":{"cellView":"form","executionInfo":{"elapsed":13125,"status":"ok","timestamp":1715036378711,"user":{"displayName":"Xinwei Song","userId":"15192157271862011156"},"user_tz":-120},"id":"3AYalLKO8FQs"},"outputs":[],"source":["%%capture\n","#@markdown ### Out of memory Kill and reset\n","!pip install csbdeep\n","try:\n","    shutil.rmtree('/content/test/')\n","    shutil.rmtree('/content/last/')\n","    shutil.rmtree('/content/data/')\n","except:\n","    pass\n","\n","! unzip -o -q data.zip\n","! unzip -o -q last.zip\n","! unzip -o -q test.zip\n","if torch.cuda.is_available():\n","    current_device = torch.cuda.current_device()\n","    print(\"Device Index:\", current_device)\n","    print(\"Device Name:\", torch.cuda.get_device_name(current_device))\n","    print(\"Device Memory Allocated:\", torch.cuda.memory_allocated(current_device))\n","    print(\"Device Memory Cached:\", torch.cuda.memory_reserved(current_device))\n","    torch.cuda.empty_cache()\n","    print(\"Device Memory Cached after empty:\", torch.cuda.memory_reserved(current_device))"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["iHOB8567GtpL"],"authorship_tag":"ABX9TyOpuXHuDagKTFJINMHJ6jVH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}